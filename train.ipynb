{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a3e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# Load the preprocessed AnnData\n",
    "input_path = '../data/GSE214979_ADHC/celltype_split_h5ad/Excitatory_filtered_BA46_ADHC_cellsentenced.h5ad'\n",
    "adata = sc.read_h5ad(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b4e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epiagent_lora.dataset import CellDatasetForUFEWithLabel, collate_fn_ufe_with_label\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1) Status → 정수 라벨로 맵\n",
    "status_series = adata.obs['Status'].astype(str)\n",
    "classes = {s:i for i, s in enumerate(sorted(status_series.unique()))}\n",
    "labels = status_series.map(classes).tolist()\n",
    "\n",
    "# 2) Dataset & Loader\n",
    "# Extract cell sentences from the AnnData object\n",
    "cell_sentences = adata.obs['cell_sentences'].tolist()\n",
    "\n",
    "# Create the training dataset\n",
    "train_cell_dataset = CellDatasetForUFEWithLabel(\n",
    "    adata=adata,\n",
    "    cell_sentences=cell_sentences,\n",
    "    labels=labels,\n",
    "    max_length=8192,\n",
    "    alpha_for_CCA=1,\n",
    "    num_cCRE=1355445,\n",
    "    is_random=True,        # (선택) 약한 증강\n",
    ")\n",
    "\n",
    "# Create the training DataLoader\n",
    "train_batch_size = 5\n",
    "train_loader = DataLoader(\n",
    "    train_cell_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    collate_fn=collate_fn_ufe_with_label, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e32bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epiagent_lora.model import EpiAgent\n",
    "import torch\n",
    "\n",
    "# Specify the path to the pre-trained model\n",
    "model_path = '../weights/pretrained_EpiAgent.pth'\n",
    "\n",
    "# Set the device (GPU if available)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Initialize the EpiAgent model with appropriate configurations\n",
    "pretrained_model = EpiAgent(\n",
    "    vocab_size=1355449,\n",
    "    num_layers=18,\n",
    "    embedding_dim=512,\n",
    "    num_attention_heads=8,\n",
    "    max_rank_embeddings=8192,\n",
    "    use_flash_attn=True,\n",
    "    pos_weight_for_RLM=torch.tensor(1.),\n",
    "    pos_weight_for_CCA=torch.tensor(1.)\n",
    ")\n",
    "\n",
    "# Load the pre-trained weights into the model\n",
    "pretrained_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Ensure the CCA loss uses a positive weight of 1\n",
    "pretrained_model.criterion_CCA.pos_weight = torch.tensor(1.)\n",
    "\n",
    "# Move the model to the specified device\n",
    "pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902017a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.FEATURE_EXTRACTION,   \n",
    "    r=16, lora_alpha=32, lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    # target_modules=[\"Wqkv\", \"out_proj\", \"fc1\", \"fc2\"]  \n",
    "    target_modules=[\"out_proj\", \"fc1\", \"fc2\"]  \n",
    ")\n",
    "\n",
    "pretrained_model = get_peft_model(pretrained_model, lora_config)\n",
    "\n",
    "pretrained_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3227f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peft 주입 후, 안전하게 한 번 더 확인: 기본 파라미터 모두 동결\n",
    "for n, p in pretrained_model.named_parameters():\n",
    "    if 'lora_' in n:  # LoRA 아답터 텐서\n",
    "        p.requires_grad = True\n",
    "    else:\n",
    "        p.requires_grad = False\n",
    "\n",
    "# CCA/SR 헤드도 명시적으로 동결(보강)\n",
    "for m in [pretrained_model.fc1_for_CCA, pretrained_model.fc2_for_CCA,\n",
    "          pretrained_model.fc1_for_RLM, pretrained_model.fc2_for_RLM,\n",
    "          pretrained_model.signal_decoder,\n",
    "          pretrained_model.layer_norm_for_CCA, pretrained_model.layer_norm_for_RLM]:\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af70939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epiagent_lora.train import train_with_contrastive_cca_sr\n",
    "from epiagent_lora.model import SupConLoss\n",
    "criterion_con = SupConLoss(temperature=0.07)\n",
    "\n",
    "trained = train_with_contrastive_cca_sr(\n",
    "    model=pretrained_model,\n",
    "    train_loader=train_loader,\n",
    "    device=device,\n",
    "    lr=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    use_noam=False,                   \n",
    "    warmup_steps=10000,\n",
    "    criterion_con=criterion_con,\n",
    "    lambda_con=1.0, lambda_cca=1.0, lambda_sr=1.0,\n",
    "    epochs=20, log_every=50,\n",
    "    grad_clip=None,                   \n",
    "    save_dir=\"./weights/exp1\",\n",
    "    save_every_steps=2000,\n",
    "    enable_logging=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c54a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./weights/exp1/final_lora\"\n",
    "\n",
    "trained.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee1d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epiagent_lora.inference import infer_cell_embeddings_from_trainloader\n",
    "\n",
    "trained.eval()\n",
    "\n",
    "cell_embeddings = infer_cell_embeddings_from_trainloader(\n",
    "    trained, device, train_loader,\n",
    "    normalize=True, use_cls=True, rebuild_noshuffle=True  \n",
    ")\n",
    "\n",
    "adata.obsm['cell_embeddings_fine_tuned'] = cell_embeddings  # (N, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c78aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "sc.pp.neighbors(adata, use_rep='cell_embeddings_fine_tuned', n_neighbors=15, metric='cosine')\n",
    "sc.tl.umap(adata, random_state=0)\n",
    "sc.pl.umap(adata, color=['Status'], frameon=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvpa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
